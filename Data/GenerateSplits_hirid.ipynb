{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafb0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splits_generation\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7890a",
   "metadata": {},
   "source": [
    "## App2. Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b806a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPSIS DEFINITION\n",
    "# Question 1) How many hours do we propagate a True atb backwards and forwards? \n",
    "# Parameters defined as Nts_pre and Nts_post. \n",
    "# Question 2) How many hours do we propagate from sepsis_onset?\n",
    " \n",
    "sep_def = {\n",
    "    # Parameteres for antibiotic propagation\n",
    "    'Nts_pre': 24, 'Nts_post': 24,\n",
    "    # Parametere for sepsis propagation\n",
    "    'N_prog_sep': 12, \n",
    "    # Parameter for determine sepsis onset\n",
    "    'increm_sofa': 2,\n",
    "    # Time step of reference: ICU admission (True) or pre-ICU admission (False)\n",
    "    'ref_sofa_icu': False\n",
    "}\n",
    " \n",
    "keys_to_select_filter = ['stay_id', 'stay_time',\n",
    "'hr_raw','o2sat_raw','temp_raw','sbp_raw','map_raw','dbp_raw','resp_raw','etco2_raw','fio2_raw',\n",
    "'be_raw', 'bicar_raw','ph_raw','pco2_raw','cl_raw','mg_raw','phos_raw','k_raw','ast_raw','bun_raw',\n",
    "'alp_raw','ca_raw','crea_raw','bildir_raw','glu_raw','lact_raw', 'bili_raw','tri_raw','hct_raw',\n",
    "'hgb_raw','ptt_raw','wbc_raw','fgn_raw','plt_raw','age_static','female_static','cai_raw','na_raw',\n",
    "'po2_raw','alb_raw','alt_raw','ck_raw','ckmb_raw','crp_raw','tnt_raw','urine_raw','basos_raw',\n",
    "'bnd_raw','eos_raw','esr_raw','hbco_raw','inrpt_raw','lymph_raw','mch_raw','mchc_raw',\n",
    "'mcv_raw','methb_raw','neut_raw','pt_raw','rbc_raw','rdw_raw','tco2_raw','weight_static','height_static', 'abx', 'sofa']\n",
    "\n",
    "keys_to_select = ['stay_id', 'stay_time','hr_raw', 'o2sat_raw','dbp_raw', 'map_raw', 'resp_raw', 'fio2_raw',  'crp_raw',\n",
    "                  'po2_raw','bili_raw', 'plt_raw', 'crea_raw', 'temp_raw',\n",
    "                  #'age_static','female_static','weight_static','height_static', \n",
    "                  'sep_onset','sep_%2s' % str(sep_def['N_prog_sep'])]\n",
    "\n",
    " \n",
    "params_to_configure = {\n",
    "    # File to laod\n",
    "    'path': '../datasets/hirid_0.5.6.parquet',\n",
    "    'w_pre_onset':  None,  # Number of windows pre sep_onset = 1\n",
    "    'w_post_onset':  None,  # Number of windows post sep_onset = 1\n",
    "    'keys': keys_to_select,\n",
    "    'label':  ['sep_onset','sep_'+str(sep_def['N_prog_sep'])],\n",
    "    'f_tr_te':  ['stay_id', 'stay_time','sep_onset','sep_%2s' % str(sep_def['N_prog_sep']), 'w_id'],\n",
    "    # sliding window\n",
    "    'moving_span': 1,\n",
    "    # min_length_pat\n",
    "    'min_length_pat': 0, # default: 0\n",
    "    # Type of imputation\n",
    "    'imputationType': \"LVCF\",\n",
    "    # filter or not patients with less of th information    \n",
    "    \"filter_pat_nans\": False, # if true, fix a threshold (next)\n",
    "    # Threshold: remove patients with less information that theshold value\n",
    "    'th': 50,\n",
    "    # Only select patients with sepsis\n",
    "    \"filter_pat\": False,\n",
    "    \"length_window\": 7,\n",
    "}\n",
    " \n",
    "seeds = [34, 56, 78]\n",
    "folders = [\"s1\", \"s2\", \"s3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a7e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of patients: 27374\n"
     ]
    }
   ],
   "source": [
    "# keys_by_split = []\n",
    "# idx_exp = 2\n",
    "\n",
    "# params_to_configure['min_length_pat'] = 0\n",
    "# df, min_length_pat = splits_generation.preprocessing(params_to_configure, \n",
    "#                                                     sep_def,  \n",
    "#                                                     debug=False)\n",
    "\n",
    "# Load data\n",
    "params = params_to_configure\n",
    "df = pd.read_parquet(params['path'])\n",
    "print(\"# of patients:\", len(df.stay_id.unique()))\n",
    "df = utils.get_SI(df, sep_def['Nts_pre'], sep_def['Nts_post'])\n",
    "# if sep_def['ref_sofa_icu']:\n",
    "#     df = df[df.stay_time >= 0].reset_index(drop=True)\n",
    "df['bsofa'] = df.groupby('stay_id')['sofa'].apply(utils.f_baseline_sofa).reset_index(level=0, drop=True)\n",
    "df = utils.get_sep(df, sep_def['N_prog_sep'], sep_def['increm_sofa'])\n",
    "df = df.drop([\"bsofa\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ea164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_0 = df[keys_to_select_filter]\n",
    "aux_1 = utils.get_SI(aux_0, sep_def['Nts_pre'], sep_def['Nts_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4726eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_1['bsofa'] = aux_1.groupby('stay_id')['sofa'].apply(utils.f_baseline_sofa).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "507193d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_2 = utils.get_sep(aux_1, sep_def['N_prog_sep'], sep_def['increm_sofa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5773a4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27374"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"# of patients with sepsis\", (len(aux_2[aux_2.sep_onset == 1].stay_id.unique()))\n",
    "print(\"# of patients without sepsis\", len(aux_2[aux_2.sep_onset == 0].stay_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4a8183d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_sw \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mslidingWindow(aux_2, params_to_configure[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoving_span\u001b[39m\u001b[38;5;124m'\u001b[39m], params_to_configure[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_window\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/PhD_ICL/AI4MedicalPrediction/Data/utils.py:95\u001b[0m, in \u001b[0;36mslidingWindow\u001b[0;34m(df, moving_span, window_length)\u001b[0m\n\u001b[1;32m     92\u001b[0m         df_aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(id_pat) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(j)\n\u001b[1;32m     93\u001b[0m         df_sw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_sw, df_aux],ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m     df_sw_ttl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_sw_ttl, df_sw],ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_sw_ttl\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/concat.py:223\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    217\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#  than concat_compat\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_sw = utils.slidingWindow(aux_2, params_to_configure['moving_span'], params_to_configure['length_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filterWindows(df_sw):\n",
    "# Get the unique stay_ids where sep_onset is 1\n",
    "pats = df_sw[df_sw.sep_onset == 1].stay_id.unique()\n",
    "\n",
    "# Create a list to store the filtered DataFrames\n",
    "result_list = []\n",
    "\n",
    "for pat_id in pats:\n",
    "    # Filter the DataFrame by each stay_id\n",
    "    pat = df_sw[df_sw.stay_id == pat_id].reset_index(drop=True)\n",
    "\n",
    "    # Find the index of the last occurrence of sep_onset = 1\n",
    "    last_sep_onset_idx = pat[pat['sep_onset'] == 1].index[-1]\n",
    "\n",
    "    # Get the next w_id after the last sep_onset = 1\n",
    "    w_id = pat.iloc[last_sep_onset_idx].w_id.split(\"_\")\n",
    "    next_w_id = w_id[0] + \"_\" + str(int(w_id[1]) + 1)\n",
    "\n",
    "    # Check if the next w_id exists in the DataFrame\n",
    "    if next_w_id in pat['w_id'].values:\n",
    "        idx = pat[pat['w_id'] == next_w_id].index[0]\n",
    "        # Filter the DataFrame to include only the rows before the next w_id\n",
    "        result_df = pat.iloc[:idx]\n",
    "    else:\n",
    "        # If the next w_id does not exist, include all rows after the last sep_onset = 1\n",
    "        result_df = pat.iloc[last_sep_onset_idx + 1:]\n",
    "\n",
    "    # Add the filtered DataFrame to the results list\n",
    "    result_list.append(result_df)\n",
    "    break\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "# final_result_df = pd.concat(result_list, ignore_index=True)\n",
    "#     return final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec71bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9ac24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4c4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9a78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14439c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.to_parquet('df_app2_hirid.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58884a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seeds)):\n",
    "    print(\"split...\", folders[i])    \n",
    "    params_to_configure['min_length_pat'] = params_to_configure['length_window']\n",
    "    X_train, X_test, y_train, y_test, keys, w_id_tr, w_id_te = splits_generation.get_tr_te(df_filter,\n",
    "                                                                        params_to_configure, \n",
    "                                                                        seeds[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    keys_by_split.append(keys)\n",
    "    print(\"X_train:\", X_train.shape)\n",
    "    print(\"X_test:\", X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    \n",
    "    np.save(\n",
    "       \"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_train_tensor.npy\", X_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_train_tensor.npy\", y_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_test_tensor.npy\", X_test\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_test_tensor.npy\", y_test\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(keys).to_csv(\"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/keys.csv\")\n",
    "    w_id_tr.to_csv(\"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/w_id_tr.csv\")\n",
    "    w_id_te.to_csv(\"./splits/hirid/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/w_id_te.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd91098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
