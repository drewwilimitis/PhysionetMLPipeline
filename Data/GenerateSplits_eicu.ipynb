{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafb0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splits_generation\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f5061",
   "metadata": {},
   "source": [
    "# App1. No sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPSIS DEFINITION\n",
    "# Question 1) How many hours do we propagate a True atb backwards and forwards? \n",
    "# Parameters defined as Nts_pre and Nts_post. \n",
    "# Question 2) How many hours do we propagate from sepsis_onset?\n",
    " \n",
    "sep_def = {\n",
    "    # Parameteres for antibiotic propagation\n",
    "    'Nts_pre': 24, 'Nts_post': 24,\n",
    "    # Parametere for sepsis propagation\n",
    "    'N_prog_sep': 12, \n",
    "    # Parameter for determine sepsis onset\n",
    "    'increm_sofa': 2,\n",
    "    # Time step of reference: ICU admission (True) or pre-ICU admission (False)\n",
    "    'ref_sofa_icu': False\n",
    "}\n",
    " \n",
    "keys_to_select = ['stay_id', 'stay_time',\n",
    "'hr_raw','o2sat_raw','temp_raw','sbp_raw','map_raw','dbp_raw','resp_raw','etco2_raw','fio2_raw',\n",
    "'be_raw', 'bicar_raw','ph_raw','pco2_raw','cl_raw','mg_raw','phos_raw','k_raw','ast_raw','bun_raw',\n",
    "'alp_raw','ca_raw','crea_raw','bildir_raw','glu_raw','lact_raw', 'bili_raw','tri_raw','hct_raw',\n",
    "'hgb_raw','ptt_raw','wbc_raw','fgn_raw','plt_raw','age_static','female_static','cai_raw','na_raw',\n",
    "'po2_raw','alb_raw','alt_raw','ck_raw','ckmb_raw','crp_raw','tnt_raw','urine_raw','basos_raw',\n",
    "'bnd_raw','eos_raw','esr_raw','hbco_raw','inrpt_raw','lymph_raw','mch_raw','mchc_raw',\n",
    "'mcv_raw','methb_raw','neut_raw','pt_raw','rbc_raw','rdw_raw','tco2_raw','weight_static','height_static', \n",
    "'SI','sep_onset','sep_%2s' % str(sep_def['N_prog_sep'])]\n",
    "\n",
    "keys_to_select = ['stay_id', 'stay_time','hr_raw', 'o2sat_raw','dbp_raw', 'map_raw', 'resp_raw', 'fio2_raw',  'crp_raw',\n",
    "                  'po2_raw','bili_raw', 'plt_raw', 'crea_raw',\n",
    "                  'age_static','female_static','weight_static','height_static', \n",
    "                  'sep_onset','sep_%2s' % str(sep_def['N_prog_sep'])]\n",
    "\n",
    " \n",
    "params_to_configure = {\n",
    "    # File to laod\n",
    "    'path': '../datasets/eicu_0.5.6.parquet',\n",
    "    'w_pre_onset':  None,  # Number of windows pre sep_onset = 1\n",
    "    'w_post_onset':  None,  # Number of windows post sep_onset = 1\n",
    "    'keys': keys_to_select,\n",
    "    'label':  ['sep_onset','sep_'+str(sep_def['N_prog_sep'])],\n",
    "    'f_tr_te':  ['stay_id', 'stay_time','sep_onset','sep_%2s' % str(sep_def['N_prog_sep'])],\n",
    "    # sliding window\n",
    "    'moving_span': None,\n",
    "    # min_length_pat\n",
    "    'min_length_pat': 0, # 0 value significa calcular\n",
    "    # Type of imputation\n",
    "    'imputationType': \"LVCF\",\n",
    "    # Threshold: remove patients with less information that theshold value\n",
    "    'th': 50,\n",
    "    # Only select patients with sepsis\n",
    "    \"filter_pat\": False,\n",
    "    \"length_window\": 7,\n",
    "}\n",
    " \n",
    "seeds = [34, 56, 78]\n",
    "folders = [\"s1\", \"s2\", \"s3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bc265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys_by_split = []\n",
    "idx_exp = 1\n",
    "for i in range(len(seeds)):\n",
    "    print(\"split...\", folders[i])\n",
    "    params_to_configure['min_length_pat'] = 0\n",
    "    df, min_length_pat = splits_generation.preprocessing(params_to_configure, \n",
    "                                                        sep_def,  \n",
    "                                                        debug=False)\n",
    "    \n",
    "    df_data = splits_generation.processing_first_approach(df, params_to_configure)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, keys = splits_generation.get_tr_te_firstapp(df_data, \n",
    "                                                                                   params_to_configure,\n",
    "                                                                                   seeds[i])\n",
    "        \n",
    "        \n",
    "#     df_final = utils.slidingWindow(df, params['moving_span'], min_length_pat)\n",
    "#     df_filter = utils.filter_windows(df_final, params_to_configure['w_pre_onset'], params_to_configure['w_post_onset'])\n",
    "#     X_train, X_test, y_train, y_test, keys = splits_generation.get_tr_te(df_filter,\n",
    "#                                                                         params_to_configure, \n",
    "#                                                                         seeds[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    keys_by_split.append(keys)\n",
    "    print(\"X_train:\", X_train.shape)\n",
    "    print(\"X_test:\", X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    \n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_train_tensor.npy\", X_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_train_tensor.npy\", y_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_test_tensor.npy\", X_test\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_test_tensor.npy\", y_test\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(keys).to_csv(\"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/keys.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7890a",
   "metadata": {},
   "source": [
    "## App2. Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b806a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPSIS DEFINITION\n",
    "# Question 1) How many hours do we propagate a True atb backwards and forwards? \n",
    "# Parameters defined as Nts_pre and Nts_post. \n",
    "# Question 2) How many hours do we propagate from sepsis_onset?\n",
    " \n",
    "sep_def = {\n",
    "    # Parameteres for antibiotic propagation\n",
    "    'Nts_pre': 24, 'Nts_post': 24,\n",
    "    # Parametere for sepsis propagation\n",
    "    'N_prog_sep': 12, \n",
    "    # Parameter for determine sepsis onset\n",
    "    'increm_sofa': 2,\n",
    "    # Time step of reference: ICU admission (True) or pre-ICU admission (False)\n",
    "    'ref_sofa_icu': False\n",
    "}\n",
    " \n",
    "keys_to_select_filter = ['stay_id', 'stay_time',\n",
    "'hr_raw','o2sat_raw','temp_raw','sbp_raw','map_raw','dbp_raw','resp_raw','etco2_raw','fio2_raw',\n",
    "'be_raw', 'bicar_raw','ph_raw','pco2_raw','cl_raw','mg_raw','phos_raw','k_raw','ast_raw','bun_raw',\n",
    "'alp_raw','ca_raw','crea_raw','bildir_raw','glu_raw','lact_raw', 'bili_raw','tri_raw','hct_raw',\n",
    "'hgb_raw','ptt_raw','wbc_raw','fgn_raw','plt_raw','age_static','female_static','cai_raw','na_raw',\n",
    "'po2_raw','alb_raw','alt_raw','ck_raw','ckmb_raw','crp_raw','tnt_raw','urine_raw','basos_raw',\n",
    "'bnd_raw','eos_raw','esr_raw','hbco_raw','inrpt_raw','lymph_raw','mch_raw','mchc_raw',\n",
    "'mcv_raw','methb_raw','neut_raw','pt_raw','rbc_raw','rdw_raw','tco2_raw','weight_static','height_static', 'abx', 'sofa']\n",
    "\n",
    "keys_to_select = ['stay_id', 'stay_time','hr_raw', 'o2sat_raw','dbp_raw', 'map_raw', 'resp_raw', 'fio2_raw',  'crp_raw',\n",
    "                  'po2_raw','bili_raw', 'plt_raw', 'crea_raw', 'temp_raw',\n",
    "                  #'age_static','female_static','weight_static','height_static', \n",
    "                  'sep_onset','sep_%2s' % str(sep_def['N_prog_sep'])]\n",
    "\n",
    " \n",
    "params_to_configure = {\n",
    "    # File to laod\n",
    "    'path': '../datasets/hirid_0.5.6.parquet',\n",
    "    'w_pre_onset':  None,  # Number of windows pre sep_onset = 1\n",
    "    'w_post_onset':  None,  # Number of windows post sep_onset = 1\n",
    "    'keys': keys_to_select,\n",
    "    'label':  ['sep_onset','sep_'+str(sep_def['N_prog_sep'])],\n",
    "    'f_tr_te':  ['stay_id', 'stay_time','sep_onset','sep_%2s' % str(sep_def['N_prog_sep']), 'w_id'],\n",
    "    # sliding window\n",
    "    'moving_span': 1,\n",
    "    # min_length_pat\n",
    "    'min_length_pat': 0, # default: 0\n",
    "    # Type of imputation\n",
    "    'imputationType': \"LVCF\",\n",
    "    # filter or not patients with less of th information    \n",
    "    \"filter_pat_nans\": False, # if true, fix a threshold (next)\n",
    "    # Threshold: remove patients with less information that theshold value\n",
    "    'th': 50,\n",
    "    # Only select patients with sepsis\n",
    "    \"filter_pat\": False,\n",
    "    \"length_window\": 7,\n",
    "}\n",
    " \n",
    "seeds = [34, 56, 78]\n",
    "folders = [\"s1\", \"s2\", \"s3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82b3ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of patients: 47827\n",
      "# of icu-patients: 47827\n",
      "# of patients pre filter by information: 47827\n",
      "# of patients post filter by information: 35380\n",
      "# of patients post imputation: 35380\n"
     ]
    }
   ],
   "source": [
    "df, min_length_pat = splits_generation.preprocessing(params_to_configure, \n",
    "                                                    sep_def,  \n",
    "                                                    debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfe5ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1871144/704914714.py\", line 1, in <module>\n",
      "    df_sw = utils.slidingWindow(df, params_to_configure['moving_span'], params_to_configure['length_window'])\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/PhD_ICL/AI4MedicalPrediction/Data/utils.py\", line 95, in slidingWindow\n",
      "    df_sw_ttl = pd.concat([df_sw_ttl, df_sw],ignore_index=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
      "    stacklevel=find_stack_level(),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py\", line 381, in concat\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py\", line 616, in get_result\n",
      "    obj = sample._constructor({name: obj}, copy=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/pandas/core/internals/concat.py\", line 223, in concatenate_managers\n",
      "    axis=i,\n",
      "            \n",
      "  File \"<__array_function__ internals>\", line 200, in concatenate\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/oescudero/anaconda3/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "df_sw = utils.slidingWindow(df, params_to_configure['moving_span'], params_to_configure['length_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filterWindows(df_sw):\n",
    "# Get the unique stay_ids where sep_onset is 1\n",
    "pats = df_sw[df_sw.sep_onset == 1].stay_id.unique()\n",
    "\n",
    "# Create a list to store the filtered DataFrames\n",
    "result_list = []\n",
    "\n",
    "for pat_id in pats:\n",
    "    # Filter the DataFrame by each stay_id\n",
    "    pat = df_sw[df_sw.stay_id == pat_id].reset_index(drop=True)\n",
    "\n",
    "    # Find the index of the last occurrence of sep_onset = 1\n",
    "    last_sep_onset_idx = pat[pat['sep_onset'] == 1].index[-1]\n",
    "\n",
    "    # Get the next w_id after the last sep_onset = 1\n",
    "    w_id = pat.iloc[last_sep_onset_idx].w_id.split(\"_\")\n",
    "    next_w_id = w_id[0] + \"_\" + str(int(w_id[1]) + 1)\n",
    "\n",
    "    # Check if the next w_id exists in the DataFrame\n",
    "    if next_w_id in pat['w_id'].values:\n",
    "        idx = pat[pat['w_id'] == next_w_id].index[0]\n",
    "        # Filter the DataFrame to include only the rows before the next w_id\n",
    "        result_df = pat.iloc[:idx]\n",
    "    else:\n",
    "        # If the next w_id does not exist, include all rows after the last sep_onset = 1\n",
    "        result_df = pat.iloc[last_sep_onset_idx + 1:]\n",
    "\n",
    "    # Add the filtered DataFrame to the results list\n",
    "    result_list.append(result_df)\n",
    "    break\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "# final_result_df = pd.concat(result_list, ignore_index=True)\n",
    "#     return final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a360c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe4b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40698c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e467f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58884a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seeds)):\n",
    "    print(\"split...\", folders[i])    \n",
    "    params_to_configure['min_length_pat'] = params_to_configure['length_window']\n",
    "    X_train, X_test, y_train, y_test, keys, w_id_tr, w_id_te = splits_generation.get_tr_te(df_filter,\n",
    "                                                                        params_to_configure, \n",
    "                                                                        seeds[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    keys_by_split.append(keys)\n",
    "    print(\"X_train:\", X_train.shape)\n",
    "    print(\"X_test:\", X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    \n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_train_tensor.npy\", X_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_train_tensor.npy\", y_train\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/X_test_tensor.npy\", X_test\n",
    "    )\n",
    "    np.save(\n",
    "       \"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/y_test_tensor.npy\", y_test\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(keys).to_csv(\"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/keys.csv\")\n",
    "    w_id_tr.to_csv(\"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/w_id_tr.csv\")\n",
    "    w_id_te.to_csv(\"./splits/App\"+str(idx_exp)+\"/\"+ folders[i] + \"/w_id_te.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51053f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "pats = df_filter.stay_id.unique()\n",
    "df_filter_aux = df_filter[df_filter.stay_id.isin(pats[0:100])]\n",
    "X_train, X_test, y_train, y_test, keys, w_id_tr, w_id_te = get_tr_te(df_filter_aux, params_to_configure, 32, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tr_te(df, params, seed, debug=True):\n",
    "df = df_filter_aux.copy()\n",
    "params = params_to_configure\n",
    "debug = True\n",
    "seed = 32\n",
    "'''\n",
    "Rules: \n",
    "    - Split the same patients into windows. For them, we define a window length as a parameter.\n",
    "    - The same patient with all windows can only be included in a single split (either train or test).\n",
    "    - We will allocate 80% for training and 20% for testing.\n",
    "    - We won't balance the datasets.\n",
    "'''\n",
    "\n",
    "# Split the patients into training and testing sets\n",
    "train_stay_ids, test_stay_ids = \\\n",
    "    train_test_split(df.stay_id.unique(), \n",
    "                     test_size=0.2, \n",
    "                     random_state=seed)\n",
    "\n",
    "# Filter the DataFrame based on the stay_ids in the training and testing sets\n",
    "train_df = df[df['stay_id'].isin(train_stay_ids)].reset_index(drop=True)\n",
    "y_train_df = train_df[params['f_tr_te']].reset_index(drop=True)\n",
    "train_df = train_df.drop(params['label'], axis=1)\n",
    "\n",
    "test_df = df[df['stay_id'].isin(test_stay_ids)].reset_index(drop=True)\n",
    "y_test_df = test_df[params['f_tr_te']].reset_index(drop=True)\n",
    "test_df = test_df.drop(params['label'], axis=1)\n",
    "\n",
    "\n",
    "if debug:\n",
    "    # Print the number of patients in the training and testing sets\n",
    "    print(\"# of windowing patients (train):\", len(train_df.w_id.unique()), \"- # of original patients:\", len(train_df.stay_id.unique()))\n",
    "    print(\"# of windowing patients (test):\", len(test_df.w_id.unique()), \"- # of original patients:\", len(test_df.stay_id.unique()))\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[list(train_df.keys())[2:-1]])\n",
    "X_train_scaled = scaler.transform(train_df[list(train_df.keys())[2:-1]])\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=train_df.columns[2:-1])\n",
    "X_train_scaled = pd.concat([X_train_scaled, train_df[['stay_id', 'stay_time', 'w_id']]], axis=1)\n",
    "\n",
    "X_test_scaled = scaler.transform(test_df[list(test_df.keys())[2:-1]])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=test_df.columns[2:-1])\n",
    "X_test_scaled = pd.concat([X_test_scaled, test_df[['stay_id', 'stay_time', 'w_id']]], axis=1)\n",
    "\n",
    "w_id_tr = X_train_scaled[['stay_id', 'stay_time', 'w_id']]\n",
    "w_id_te = X_test_scaled[['stay_id', 'stay_time', 'w_id']]\n",
    "\n",
    "# Convert the DataFrames into tensors while discarding the first two and last features\n",
    "X_train = utils.dataframe_to_tensor(X_train_scaled, params['min_length_pat'], 'w_id')\n",
    "X_train = X_train[:, :, 0:X_train.shape[2]-3]\n",
    "X_test = utils.dataframe_to_tensor(X_test_scaled, params['min_length_pat'], 'w_id')\n",
    "X_test = X_test[:, :, 0:X_test.shape[2]-3]\n",
    "\n",
    "y_train = utils.dataframe_to_tensor(y_train_df, params['min_length_pat'], 'w_id')\n",
    "y_train = y_train[:, :, -3]\n",
    "y_test = utils.dataframe_to_tensor(y_test_df, params['min_length_pat'], 'w_id')\n",
    "y_test = y_test[:, :, -3]\n",
    "# return  X_train, X_test, y_train, y_test, train_df.columns, w_id_tr, w_id_te\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27293242",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439474ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_configure['min_length_pat'] = params_to_configure['length_window']\n",
    "X_train, X_test, y_train, y_test, keys, w_id_tr, w_id_te = get_tr_te(df_filter_aux,\n",
    "                                                                        params_to_configure, \n",
    "                                                                        seeds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc768df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter[df_filter.stay_id == 151303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961eafa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
