{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d3aa00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import pyten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba2e4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concatenate_files(directory):\n",
    "    all_data = []  # List to hold all the dataframes\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.psv'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            \n",
    "            # Load the PSV file into a DataFrame\n",
    "            df = pd.read_csv(filepath, sep='|')\n",
    "            # Add a column with the filename as a value\n",
    "            df['id_pat'] = filename.split(\".\")[0]\n",
    "            # Append the DataFrame to the list\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Concatenate all the DataFrames in the list row-wise\n",
    "    concatenated_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df\n",
    "\n",
    "\n",
    "def getlabel(x):\n",
    "    labels = (x == True).cumsum()\n",
    "    return (labels > 0).astype(int)\n",
    "\n",
    "def group(df_grupo, fre):\n",
    "    return df_grupo.groupby(df_grupo.index // freq).median()\n",
    "\n",
    "def temporalDataset(df_grupo, maxLength=15, flag=666):\n",
    "    if len(df_grupo) < maxLength:\n",
    "        # Completar con 666 si hay menos de maxLength filas\n",
    "        fill_values = {col: [flag] * (maxLength - len(df_grupo)) for col in df_grupo.columns[1:]}  \n",
    "        df_grupo = df_grupo.append(pd.DataFrame({'id_pat': [df_grupo['id_pat'].iloc[0]] * (maxLength - len(df_grupo)), **fill_values}), ignore_index=True)\n",
    "    else: \n",
    "        df_grupo = df_grupo.head(maxLength)\n",
    "    return df_grupo\n",
    "\n",
    "\n",
    "def dataframeToTensor(df, timeStepLength):\n",
    "    _, id_pat = np.unique(df.id_pat, return_index=True)\n",
    "    listPatients = np.array(df.id_pat)[np.sort(id_pat)]\n",
    "\n",
    "    index = df.index\n",
    "    for i in range(len(listPatients)):\n",
    "        df_trial = df[df.id_pat == listPatients[i]]\n",
    "\n",
    "        if i == 0:\n",
    "            X = np.array(df_trial)\n",
    "            X = X.reshape(1, timeStepLength, df.shape[1])\n",
    "        else:\n",
    "            X_2 = np.array(df_trial)\n",
    "            X_2 = X_2.reshape(1, timeStepLength, df.shape[1])\n",
    "            X = np.append(X, X_2, axis=0)\n",
    "    \n",
    "    return np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8366e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (1432, 108)\n",
      "max # of days icu stay: 124\n",
      "average # of days icu stay: 15.349162011173185\n",
      "median # of days icu stay: 7.0\n",
      "Pre: (1432, 108)\n",
      "Post: (2040, 108)\n",
      "(136, 15, 105)\n"
     ]
    }
   ],
   "source": [
    "# Load patient information\n",
    "directory = '../../../mimic_demo'\n",
    "df = load_and_concatenate_files(directory)\n",
    "df['label'] = df.groupby('id_pat')['sep3'].apply(getlabel)\n",
    "df = df[df['startdate'] >= 0].reset_index(drop=True)\n",
    "\n",
    "# Define a frequency value\n",
    "freq = 24\n",
    "df_grouped = df.groupby('id_pat').apply(group, freq).reset_index()\n",
    "df_grouped['timeStep'] = df_grouped.groupby('id_pat').cumcount() + 1\n",
    "df_grouped = df_grouped.drop(['startdate', 'level_1'], axis=1)\n",
    "print(\"Dimensiones:\", df_grouped.shape)\n",
    "print(\"max # of days icu stay:\", df_grouped.timeStep.max())\n",
    "print(\"average # of days icu stay:\", df_grouped.timeStep.mean())\n",
    "print(\"median # of days icu stay:\", df_grouped.timeStep.median())\n",
    "df_grouped.loc[df_grouped['label'] == 0.5, 'label'] = 1\n",
    "\n",
    "# Generate a temporal dataset with a maximum number of time steps per patients\n",
    "maxLength = 15\n",
    "flag = 666\n",
    "print(\"Pre:\", df_grouped.shape)\n",
    "df_temp = df_grouped.groupby('id_pat').apply(temporalDataset, maxLength).reset_index(drop=True)\n",
    "print(\"Post:\", df_temp.shape)\n",
    "\n",
    "# Create a tensor dataset based on previous temporal data\n",
    "X = dataframeToTensor(df_temp, maxLength)\n",
    "Xf = X[:,:,1:-2]\n",
    "print(Xf.shape)\n",
    "\n",
    "# LRTC for imputation of values\n",
    "n1, n2, n3 = Xf.shape\n",
    "\n",
    "coords = np.array(np.meshgrid(range(n1), range(n2), range(n3))).reshape(3, -1).T\n",
    "df_lrtc = pd.DataFrame(coords, columns=[\"x1\", \"x2\", \"x3\"])\n",
    "df_lrtc[\"r\"] = Xf[coords[:, 0], coords[:, 1], coords[:, 2]]\n",
    "df_lrtc[\"x1\"] += 1\n",
    "df_lrtc[\"x2\"] += 1\n",
    "df_lrtc[\"x3\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b46fab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010410913967129189\n",
      "30244\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Execute tensor completion\n",
    "# for i in range(50, 500, 50):\n",
    "inicio = time.time()\n",
    "i = 350\n",
    "[OriTensor, DeTensor, TenClass, RecTensor, RecTensor_hat, mask] = pyten.UI.helios(df_lrtc, i)\n",
    "\n",
    "# Calculate the error between the real tensor and the reconstructed tensor\n",
    "# we only consider the values different from nan\n",
    "rec = RecTensor_hat * mask \n",
    "real = np.nan_to_num(Xf)\n",
    "error = np.linalg.norm(rec - real)/np.linalg.norm(real)\n",
    "print(error)\n",
    "\n",
    "if np.any(RecTensor_hat < 0):\n",
    "    num_negativos = np.count_nonzero(RecTensor_hat < 0)\n",
    "    print(num_negativos)\n",
    "else:\n",
    "    print(i)\n",
    "\n",
    "RecTensor_hat = np.where(RecTensor_hat < 0, np.abs(RecTensor_hat), RecTensor_hat)\n",
    "fin = time.time()\n",
    "\n",
    "# Calcular el tiempo transcurrido\n",
    "tiempo_transcurrido = fin - inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2ba5722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4958687196175257"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiempo_transcurrido/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9893efde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214200"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "136*15*105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b846d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
